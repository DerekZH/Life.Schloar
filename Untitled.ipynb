{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import gensim\n",
    "import sys\n",
    "import numpy as np\n",
    "import nltk\n",
    "from app.lda_w2v_recommender.helpers.helpers import *\n",
    "\n",
    "def w2v_get_semantics_for_list_of_words(model, list_of_words):\n",
    "    for word in list_of_words:\n",
    "        try:\n",
    "            vec = vec + model[word]\n",
    "        except:\n",
    "            try:    #deal with words that are excluded from w2v model because of low frequency\n",
    "                vec = model[word]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    vec = vec/float(len(list_of_words))\n",
    "    \n",
    "    return vec\n",
    "\n",
    "\n",
    "def lda_w2v_loader():\n",
    "    ######  LDA Section\n",
    "    ######  LDA Data Loading\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    def tokenize(text, stop_words):\n",
    "        return [token for token in gensim.utils.simple_preprocess(text) if token not in stop_words]\n",
    "\n",
    "    class MyCorpus(gensim.corpora.TextCorpus): \n",
    "        def get_texts(self): \n",
    "            for string in self.input.values(): # for each relevant file \n",
    "                yield tokenize(string, stop_words)\n",
    "\n",
    "    with open('Combined_Udemy_Coursera_Reviews.pickle', 'rb') as f:\n",
    "        Udemy_Coursera_combined_train = pickle.load(f)\n",
    "\n",
    "    mycorpus = MyCorpus(Udemy_Coursera_combined_train)\n",
    "    mycorpus.dictionary.filter_extremes()\n",
    "    sys.stdout.flush()\n",
    "    mycorpus.dictionary.items()\n",
    "    mycorpus_dict = gensim.corpora.dictionary.Dictionary()\n",
    "    mycorpus_dict= mycorpus_dict.load('LDA_Udemy_Coursera_20_topics_gensim_dict.dict')\n",
    "\n",
    "    lda = gensim.models.ldamulticore.LdaMulticore(id2word=mycorpus.dictionary.id2token)\n",
    "    lda = lda.load('lda_full_20_topics.lda')\n",
    "\n",
    "    LDA_results = pd.read_csv('Udemy_Coursera_4000_LDA_results.csv')\n",
    "    \n",
    "    \n",
    "    ##### Word2Vec Data Loading\n",
    "    w2v = gensim.models.Word2Vec.load('w2v_300_dimensions_wiki_data_added.word2vec')\n",
    "\n",
    "    with open('w2v_course_with_top_words_wiki_data_added.pickle', 'rb') as f:\n",
    "        w2v_course_with_top_words = pickle.load(f)\n",
    "    \n",
    "    with open('w2v_course_semantic_matrix.pickle', 'rb') as f:\n",
    "        w2v_course_semantic_matrix = pickle.load(f)\n",
    "    \n",
    "    with open('w2v_course_semantic_norm.pickle', 'rb') as f:\n",
    "        w2v_course_semantic_norm = pickle.load(f)\n",
    "\n",
    "    with open('w2v_courses.pickle', 'rb') as f:\n",
    "        w2v_courses = pickle.load(f)\n",
    "        \n",
    "    return lda, LDA_results, mycorpus_dict, w2v, w2v_course_with_top_words, w2v_course_semantic_matrix, w2v_course_semantic_norm, w2v_courses\n",
    "\n",
    "\n",
    "def lda_w2v_recommender(input_string, lda, LDA_results, mycorpus_dict, w2v, w2v_course_with_top_words, w2v_course_semantic_matrix, w2v_course_semantic_norm, w2v_courses, num_to_recommend = 5):\n",
    "\n",
    "\n",
    "#     #### LDA recommendation\n",
    "#     input_lda_assignment = topic_assignmenter(input_string, lda, mycorpus_dict)\n",
    "#     input_lda_assignment = np.array(input_lda_assignment)\n",
    "#     print 'Working hard to compare your description with course DNAs...'\n",
    "\n",
    "#     try:\n",
    "#         LDA_results.drop('cos_similarity', inplace=True, axis=1)\n",
    "#     except:\n",
    "#         pass\n",
    "#     topic_matrix = LDA_results.iloc[:,1:lda.num_topics+1].values\n",
    "#     similarity = topic_matrix.dot(input_lda_assignment)\n",
    "    \n",
    "#     LDA_results['cos_similarity'] = similarity\n",
    "#     LDA_results.sort('cos_similarity', ascending=False, inplace=True)\n",
    "\n",
    "#     lda_recom = []\n",
    "#     for i in range(num_to_recommend):\n",
    "#         lda_recom.append(LDA_results.iloc[i].course_name)\n",
    "\n",
    "\n",
    "    ##### Word2Vec Section\n",
    "\n",
    "    ##### Word2Vec Recommendation\n",
    "    vocab = w2v.vocab.keys()\n",
    "\n",
    "    couse_index_padding = 0\n",
    "    if input_string in w2v_course_with_top_words.keys():\n",
    "        print 'dada'\n",
    "        des_1 = [x for x in w2v_course_with_top_words[input_string] if x in vocab]\n",
    "        couse_index_padding = 1\n",
    "    else:\n",
    "        des_1 = [x for x in paragraph_preprocessing(input_string) if x in vocab]\n",
    "    \n",
    "    print des_1\n",
    "    \n",
    "    des_1_norm = np.linalg.norm(w2v_get_semantics_for_list_of_words(w2v, des_1))\n",
    "    similarity_results = w2v_course_semantic_matrix.dot(w2v_get_semantics_for_list_of_words(w2v, des_1))/w2v_course_semantic_norm/des_1_norm\n",
    "    semantic_score_dic = dict(zip(similarity_results, w2v_courses))\n",
    "\n",
    "    w2v_recom = []\n",
    "    for i in range(couse_index_padding, couse_index_padding+num_to_recommend):\n",
    "        w2v_recom.append(semantic_score_dic[sorted(semantic_score_dic.keys(), reverse=True)[i]])\n",
    "        print sorted(semantic_score_dic.keys(), reverse=True)[i]\n",
    "\n",
    "    return w2v_recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 210 ms, total: 11.2 s\n",
      "Wall time: 11.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lda, LDA_results, mycorpus_dict, w2v, w2v_course_with_top_words, w2v_course_semantic_matrix, w2v_course_semantic_norm, w2v_courses = lda_w2v_loader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHARE ECONOMY:Entrepreneurship Uber Airbnb TaskRabbit Lyft\n"
     ]
    }
   ],
   "source": [
    "for string in w2v_course_with_top_words.keys():\n",
    "    if query_string in string:\n",
    "        print string\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'SHARE ECONOMY:Entrepreneurship Uber Airbnb TaskRabbit Lyft'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query_string = u'SHARE ECONOMY:Entrepreneurship Uber Airbnb TaskRabbit Lyft'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dada\n",
      "[u'economi', u'share', u'collabor', u'resourc', u'group', u'lessen', u'econom', u'materi', u'member', u'burden', u'busi', u'technolog', u'learn', u'particip']\n",
      "0.712265\n",
      "0.678859\n",
      "0.678068\n",
      "0.677747\n",
      "0.67321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'Engaging Citizens:  A Game Changer for Development?',\n",
       " u'Building a Winning Start-Up ',\n",
       " u'Sustainability in Practice',\n",
       " u'The Power of Markets',\n",
       " u'Community Change in Public Health']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_w2v_recommender(query_string, lda, LDA_results, mycorpus_dict, w2v, w2v_course_with_top_words, w2v_course_semantic_matrix, w2v_course_semantic_norm, w2v_courses, num_to_recommend = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from app.lda_w2v_recommender.helpers.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from app.lda_w2v_recommender.lda_w2v_recommender import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda, LDA_results, mycorpus_dict, w2v, w2v_course_with_top_words, w2v_course_semantic_matrix, w2v_course_semantic_norm, w2v_courses = lda_w2v_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.33206118868845397,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0.43716958053932475,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_assignmenter('A+ Research Paper in Biology', lda, mycorpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_lda_assignment = np.array(topic_assignmenter('A+ Research Paper in Biology', lda, mycorpus_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.33155079,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.43767998,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lda_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595549</td>\n",
       "      <td>0</td>\n",
       "      <td>0.328496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066642</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  2  3  4  5         6  7         8  9  10 ...  17  18  19        20  \\\n",
       "467  0  0  0  0  0  0.595549  0  0.328496  0   0 ...   0   0   0  0.066642   \n",
       "\n",
       "     21  22  23  24  25  26  \n",
       "467   0   0   0   0   0   0  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_results.loc[LDA_results.course_name == 'A+ Research Paper in Biology'].iloc[:,1:lda.num_topics+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'A+ Research Paper in Biology' in LDA_results.course_name.values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
