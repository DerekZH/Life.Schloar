{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import gensim\n",
    "import sys\n",
    "import numpy as np\n",
    "import nltk\n",
    "from app.lda_w2v_recommender.helpers.helpers import *\n",
    "\n",
    "\n",
    "def w2v_get_semantics_for_list_of_words(model, list_of_words):\n",
    "    for word in list_of_words:\n",
    "        try:\n",
    "            vec = vec + model[word]\n",
    "        except:\n",
    "            try:    #deal with words that are excluded from w2v model because of low frequency\n",
    "                vec = model[word]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    vec = vec/float(len(list_of_words))\n",
    "    \n",
    "    return vec\n",
    "\n",
    "def is_ascii(s):\n",
    "    return all(ord(c) < 128 for c in s)\n",
    "\n",
    "def lda_w2v_loader():\n",
    "    ######  LDA Section\n",
    "    ######  LDA Data Loading\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    def tokenize(text, stop_words):\n",
    "        return [token for token in gensim.utils.simple_preprocess(text) if token not in stop_words]\n",
    "\n",
    "    class MyCorpus(gensim.corpora.TextCorpus): \n",
    "        def get_texts(self): \n",
    "            for string in self.input.values(): # for each relevant file \n",
    "                yield tokenize(string, stop_words)\n",
    "\n",
    "#    with open('Combined_Udemy_Coursera_Reviews.pickle', 'rb') as f:\n",
    "#        Udemy_Coursera_combined_train = pickle.load(f)\n",
    "\n",
    "    with open('Combined_Udemy_Coursera_Edx_Reviews.pickle', 'rb') as f:\n",
    "        Udemy_Coursera_combined_train = pickle.load(f)\n",
    "\n",
    "    mycorpus = MyCorpus(Udemy_Coursera_combined_train)\n",
    "    mycorpus.dictionary.filter_extremes()\n",
    "    mycorpus.dictionary.items()\n",
    "    mycorpus_dict = gensim.corpora.dictionary.Dictionary()\n",
    "#    mycorpus_dict= mycorpus_dict.load('LDA_Udemy_Coursera_20_topics_gensim_dict.dict')\n",
    "    mycorpus_dict= mycorpus_dict.load('LDA_Udemy_Coursera_Edx_26_topics_gensim_dict.dict')\n",
    "    \n",
    "    lda = gensim.models.ldamulticore.LdaMulticore(id2word=mycorpus.dictionary.id2token)\n",
    "#    lda = lda.load('lda_full_20_topics.lda')\n",
    "    lda = lda.load('LDA_Udemy_Coursera_Edx_26_topics.lda')\n",
    "#    LDA_results = pd.read_csv('Udemy_Coursera_4000_LDA_results.csv')\n",
    "    LDA_results = pd.read_csv('LDA_results_CEU_26_topics.csv')\n",
    "    \n",
    "    \n",
    "    ##### Word2Vec Data Loading\n",
    "    w2v = gensim.models.Word2Vec.load('w2v_300_dimensions_wiki_data_added.word2vec')\n",
    "\n",
    "    with open('w2v_course_with_top_words_wiki_data_added.pickle', 'rb') as f:\n",
    "        w2v_course_with_top_words = pickle.load(f)\n",
    "    \n",
    "    with open('w2v_course_semantic_matrix.pickle', 'rb') as f:\n",
    "        w2v_course_semantic_matrix = pickle.load(f)\n",
    "    \n",
    "    with open('w2v_course_semantic_norm.pickle', 'rb') as f:\n",
    "        w2v_course_semantic_norm = pickle.load(f)\n",
    "\n",
    "    with open('w2v_courses.pickle', 'rb') as f:\n",
    "        w2v_courses = pickle.load(f)\n",
    "        \n",
    "    return lda, LDA_results, mycorpus_dict, w2v, w2v_course_with_top_words, w2v_course_semantic_matrix, w2v_course_semantic_norm, w2v_courses\n",
    "\n",
    "\n",
    "def lda_w2v_recommender(input_string, lda, LDA_results, mycorpus_dict, w2v, w2v_course_with_top_words, w2v_course_semantic_matrix, w2v_course_semantic_norm, w2v_courses, num_to_recommend = 5):\n",
    "\n",
    "    #### LDA recommendation\n",
    "\n",
    "    couse_index_padding = 0\n",
    "    if input_string in w2v_course_with_top_words.keys():\n",
    "        input_lda_assignment = LDA_results.loc[LDA_results.course_name == input_string].iloc[:,1:lda.num_topics+1].values.T\n",
    "        couse_index_padding = 1\n",
    "        print 'dada'\n",
    "    else:\n",
    "        input_lda_assignment = topic_assignmenter(input_string, lda, mycorpus_dict)\n",
    "        input_lda_assignment = np.array(input_lda_assignment)\n",
    "    print 'Working hard to compare your description with course DNAs...'\n",
    "    print input_lda_assignment.shape\n",
    "\n",
    "    try:\n",
    "        LDA_results.drop('cos_similarity', inplace=True, axis=1)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    topic_matrix = LDA_results.iloc[:,1:lda.num_topics+1].values\n",
    "\n",
    "    topic_matrix_norm = []\n",
    "    for i in range(topic_matrix.shape[0]):\n",
    "        topic_matrix_norm.append(np.linalg.norm(topic_matrix[i,:]))\n",
    "\n",
    "    topic_matrix_norm = np.array(topic_matrix_norm)\n",
    "\n",
    "    similarity = topic_matrix.dot(input_lda_assignment).reshape((topic_matrix.shape[0],1)) / topic_matrix_norm.reshape((topic_matrix_norm.shape[0],1)) / np.linalg.norm(input_lda_assignment)\n",
    "    print topic_matrix.dot(input_lda_assignment).shape\n",
    "    print topic_matrix_norm.reshape((topic_matrix_norm.shape[0],1)).shape\n",
    "    print np.linalg.norm(input_lda_assignment)\n",
    "    print similarity.shape\n",
    "\n",
    "    LDA_results['cos_similarity'] = similarity\n",
    "    LDA_results.sort('cos_similarity', ascending=False, inplace=True)\n",
    "\n",
    "    lda_recom = []\n",
    "\n",
    "    off_set = 0\n",
    "    ######## code below is not a complete fix, need to update\n",
    "    for i in range(num_to_recommend):\n",
    "        if is_ascii(LDA_results.iloc[i+off_set].course_name):\n",
    "            lda_recom.append(LDA_results.iloc[i+off_set+couse_index_padding].course_name)\n",
    "        else:\n",
    "            off_set += 1\n",
    "            lda_recom.append(LDA_results.iloc[i+off_set+couse_index_padding].course_name)\n",
    "            \n",
    "#    print '\\n\\nLDA results'        \n",
    "#    for i in range(100):\n",
    "#        print LDA_results.iloc[i].course_name, LDA_results.iloc[i].cos_similarity\n",
    "#    print '\\n\\n'\n",
    "    \n",
    "    ##### Word2Vec Section\n",
    "\n",
    "    ##### Word2Vec Recommendation\n",
    "    vocab = w2v.vocab.keys()\n",
    "\n",
    "    couse_index_padding = 0\n",
    "    if input_string in w2v_course_with_top_words.keys():\n",
    "        des_1 = [x for x in w2v_course_with_top_words[input_string] if x in vocab]\n",
    "        couse_index_padding = 1\n",
    "    else:\n",
    "        des_1 = [x for x in paragraph_preprocessing(input_string) if x in vocab]\n",
    "\n",
    "\n",
    "    des_1_norm = np.linalg.norm(w2v_get_semantics_for_list_of_words(w2v, des_1))\n",
    "    similarity_results = w2v_course_semantic_matrix.dot(w2v_get_semantics_for_list_of_words(w2v, des_1))/w2v_course_semantic_norm/des_1_norm\n",
    "    semantic_score_dic = dict(zip(similarity_results, w2v_courses))\n",
    "\n",
    "    w2v_recom = []\n",
    "    off_set = 0  # off_set is used to exclude unicode strings\n",
    "    for i in range(couse_index_padding, couse_index_padding+num_to_recommend):\n",
    "        if is_ascii(semantic_score_dic[sorted(semantic_score_dic.keys(), reverse=True)[i+off_set]]):\n",
    "            w2v_recom.append(semantic_score_dic[sorted(semantic_score_dic.keys(), reverse=True)[i+off_set]])\n",
    "        else:\n",
    "            off_set += 1\n",
    "            w2v_recom.append(semantic_score_dic[sorted(semantic_score_dic.keys(), reverse=True)[i+off_set]])\n",
    "    \n",
    "    return lda_recom, w2v_recom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_cos_similariy(course_name):\n",
    "    try:\n",
    "        return semantic_score_rev_dic[course_name]\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lda, LDA_results, mycorpus_dict, w2v, w2v_course_with_top_words, w2v_course_semantic_matrix, w2v_course_semantic_norm, w2v_courses = lda_w2v_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction to Water and Climate\n",
      "Working hard to compare your description with course DNAs...\n",
      "(26,)\n",
      "(4544,)\n",
      "(4544, 1)\n",
      "0.7596153846\n",
      "(4544, 1)\n",
      "[u'Turn Down the Heat: Why a 4\\xb0C Warmer World Must be Avoided'\n",
      " u'Forests and Humans: From the Midwest to Madagascar'\n",
      " u'Global Warming: The Science and Modeling of Climate Change'\n",
      " u'Our Earth: Its Climate, History, and Processes'\n",
      " u'Climate Change in Four Dimensions'\n",
      " u'Changing Weather and Climate in the Great Lakes Region'\n",
      " u'The Dynamic Earth: A Course for Educators' u'Ocean Solutions'\n",
      " u'A Look at Nuclear Science and Technology'\n",
      " u'Pathways to climate change adaptation: the case of Small Island Developing States']\n"
     ]
    }
   ],
   "source": [
    "input_string = LDA_results.course_name.iloc[randint(0,LDA_results.shape[0])]\n",
    "print input_string\n",
    "\n",
    "num_to_recommend = 10\n",
    "\n",
    "couse_index_padding = 0\n",
    "if input_string in w2v_course_with_top_words.keys():\n",
    "    input_lda_assignment = LDA_results.loc[LDA_results.course_name == input_string].iloc[:,1:lda.num_topics+1].values.T\n",
    "    couse_index_padding = 1\n",
    "    print 'dada'\n",
    "else:\n",
    "    input_lda_assignment = topic_assignmenter(input_string, lda, mycorpus_dict)\n",
    "    input_lda_assignment = np.array(input_lda_assignment)\n",
    "print 'Working hard to compare your description with course DNAs...'\n",
    "print input_lda_assignment.shape\n",
    "\n",
    "try:\n",
    "    LDA_results.drop('cos_similarity', inplace=True, axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "topic_matrix = LDA_results.iloc[:,1:lda.num_topics+1].values\n",
    "\n",
    "topic_matrix_norm = []\n",
    "for i in range(topic_matrix.shape[0]):\n",
    "    topic_matrix_norm.append(np.linalg.norm(topic_matrix[i,:]))\n",
    "\n",
    "topic_matrix_norm = np.array(topic_matrix_norm)\n",
    "\n",
    "similarity = topic_matrix.dot(input_lda_assignment).reshape((topic_matrix.shape[0],1)) / topic_matrix_norm.reshape((topic_matrix_norm.shape[0],1)) / np.linalg.norm(input_lda_assignment)\n",
    "print topic_matrix.dot(input_lda_assignment).shape\n",
    "print topic_matrix_norm.reshape((topic_matrix_norm.shape[0],1)).shape\n",
    "print np.linalg.norm(input_lda_assignment)\n",
    "print similarity.shape\n",
    "\n",
    "LDA_results['cos_similarity'] = similarity\n",
    "LDA_results.sort('cos_similarity', ascending=False, inplace=True)\n",
    "\n",
    "lda_recom = []\n",
    "\n",
    "off_set = 0\n",
    "######## code below is not a complete fix, need to update\n",
    "for i in range(num_to_recommend):\n",
    "    if is_ascii(LDA_results.iloc[i+off_set].course_name):\n",
    "        lda_recom.append(LDA_results.iloc[i+off_set+couse_index_padding].course_name)\n",
    "    else:\n",
    "        off_set += 1\n",
    "        lda_recom.append(LDA_results.iloc[i+off_set+couse_index_padding].course_name)\n",
    "\n",
    "#    print '\\n\\nLDA results'        \n",
    "#    for i in range(100):\n",
    "#        print LDA_results.iloc[i].course_name, LDA_results.iloc[i].cos_similarity\n",
    "#    print '\\n\\n'\n",
    "\n",
    "##### Word2Vec Section\n",
    "\n",
    "##### Word2Vec Recommendation\n",
    "vocab = w2v.vocab.keys()\n",
    "\n",
    "couse_index_padding = 0\n",
    "if input_string in w2v_course_with_top_words.keys():\n",
    "    des_1 = [x for x in w2v_course_with_top_words[input_string] if x in vocab]\n",
    "    couse_index_padding = 1\n",
    "else:\n",
    "    des_1 = [x for x in paragraph_preprocessing(input_string) if x in vocab]\n",
    "\n",
    "\n",
    "des_1_norm = np.linalg.norm(w2v_get_semantics_for_list_of_words(w2v, des_1))\n",
    "similarity_results = w2v_course_semantic_matrix.dot(w2v_get_semantics_for_list_of_words(w2v, des_1))/w2v_course_semantic_norm/des_1_norm\n",
    "semantic_score_dic = dict(zip(similarity_results, w2v_courses))\n",
    "\n",
    "w2v_recom = []\n",
    "off_set = 0  # off_set is used to exclude unicode strings\n",
    "for i in range(couse_index_padding, couse_index_padding+num_to_recommend):\n",
    "    if is_ascii(semantic_score_dic[sorted(semantic_score_dic.keys(), reverse=True)[i+off_set]]):\n",
    "        w2v_recom.append(semantic_score_dic[sorted(semantic_score_dic.keys(), reverse=True)[i+off_set]])\n",
    "    else:\n",
    "        off_set += 1\n",
    "        w2v_recom.append(semantic_score_dic[sorted(semantic_score_dic.keys(), reverse=True)[i+off_set]])\n",
    "        \n",
    "semantic_score_rev_dic = {}\n",
    "for key, value in semantic_score_dic.items():\n",
    "    semantic_score_rev_dic[value] = key\n",
    "    \n",
    "LDA_results['w2v_cos_similarity'] = LDA_results.course_name.apply(get_cos_similariy)\n",
    "LDA_results['weighted_cs'] = (LDA_results.cos_similarity + LDA_results.w2v_cos_similarity)/2\n",
    "print LDA_results.sort('weighted_cs', ascending=False).course_name.iloc[:num_to_recommend].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learn to Play French Horn: Beginner to Pro Made the Easy Way\n",
      "dada\n",
      "Working hard to compare your description with course DNAs...\n",
      "(26, 1)\n",
      "(4544, 1)\n",
      "(4544, 1)\n",
      "0.709812002937\n",
      "(4544, 1)\n",
      "[u'Learn to Play French Horn: Beginner to Pro Made the Easy Way'\n",
      " u'Learn to Play Euphonium: Beginner to Pro in Under Five Hours'\n",
      " u'Master Flute Playing: Intermediate Instruction Made Simple!'\n",
      " u'From the Repertoire: Western Music History through Performance'\n",
      " u\"Music's Big Bang: The Genesis of Rock 'n' Roll\"\n",
      " u'20\\u4e16\\u7eaa\\u897f\\u65b9\\u97f3\\u4e50 Western Music in the 20th Century'\n",
      " u'Introduction to Classical Music' u'Listening to World Music'\n",
      " u'Curanderismo Part 2: Traditional Healing of the Spirit/Energy'\n",
      " u'Magic in the Middle Ages']\n"
     ]
    }
   ],
   "source": [
    "input_string = LDA_results.course_name.iloc[randint(0,LDA_results.shape[0])]\n",
    "print input_string\n",
    "\n",
    "num_to_recommend = 10\n",
    "\n",
    "couse_index_padding = 0\n",
    "if input_string in w2v_course_with_top_words.keys():\n",
    "    input_lda_assignment = LDA_results.loc[LDA_results.course_name == input_string].iloc[:,1:lda.num_topics+1].values.T\n",
    "    couse_index_padding = 1\n",
    "    print 'dada'\n",
    "else:\n",
    "    input_lda_assignment = topic_assignmenter(input_string, lda, mycorpus_dict)\n",
    "    input_lda_assignment = np.array(input_lda_assignment)\n",
    "print 'Working hard to compare your description with course DNAs...'\n",
    "print input_lda_assignment.shape\n",
    "\n",
    "try:\n",
    "    LDA_results.drop('cos_similarity', inplace=True, axis=1)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "topic_matrix = LDA_results.iloc[:,1:lda.num_topics+1].values\n",
    "\n",
    "topic_matrix_norm = []\n",
    "for i in range(topic_matrix.shape[0]):\n",
    "    topic_matrix_norm.append(np.linalg.norm(topic_matrix[i,:]))\n",
    "\n",
    "topic_matrix_norm = np.array(topic_matrix_norm)\n",
    "\n",
    "similarity = topic_matrix.dot(input_lda_assignment).reshape((topic_matrix.shape[0],1)) / topic_matrix_norm.reshape((topic_matrix_norm.shape[0],1)) / np.linalg.norm(input_lda_assignment)\n",
    "print topic_matrix.dot(input_lda_assignment).shape\n",
    "print topic_matrix_norm.reshape((topic_matrix_norm.shape[0],1)).shape\n",
    "print np.linalg.norm(input_lda_assignment)\n",
    "print similarity.shape\n",
    "\n",
    "LDA_results['cos_similarity'] = similarity\n",
    "LDA_results.sort('cos_similarity', ascending=False, inplace=True)\n",
    "\n",
    "lda_recom = []\n",
    "\n",
    "off_set = 0\n",
    "######## code below is not a complete fix, need to update\n",
    "for i in range(num_to_recommend):\n",
    "    if is_ascii(LDA_results.iloc[i+off_set].course_name):\n",
    "        lda_recom.append(LDA_results.iloc[i+off_set+couse_index_padding].course_name)\n",
    "    else:\n",
    "        off_set += 1\n",
    "        lda_recom.append(LDA_results.iloc[i+off_set+couse_index_padding].course_name)\n",
    "\n",
    "#    print '\\n\\nLDA results'        \n",
    "#    for i in range(100):\n",
    "#        print LDA_results.iloc[i].course_name, LDA_results.iloc[i].cos_similarity\n",
    "#    print '\\n\\n'\n",
    "\n",
    "##### Word2Vec Section\n",
    "\n",
    "##### Word2Vec Recommendation\n",
    "vocab = w2v.vocab.keys()\n",
    "\n",
    "couse_index_padding = 0\n",
    "if input_string in w2v_course_with_top_words.keys():\n",
    "    des_1 = [x for x in w2v_course_with_top_words[input_string] if x in vocab]\n",
    "    couse_index_padding = 1\n",
    "else:\n",
    "    des_1 = [x for x in paragraph_preprocessing(input_string) if x in vocab]\n",
    "\n",
    "\n",
    "des_1_norm = np.linalg.norm(w2v_get_semantics_for_list_of_words(w2v, des_1))\n",
    "similarity_results = w2v_course_semantic_matrix.dot(w2v_get_semantics_for_list_of_words(w2v, des_1))/w2v_course_semantic_norm/des_1_norm\n",
    "semantic_score_dic = dict(zip(similarity_results, w2v_courses))\n",
    "\n",
    "w2v_recom = []\n",
    "off_set = 0  # off_set is used to exclude unicode strings\n",
    "for i in range(couse_index_padding, couse_index_padding+num_to_recommend):\n",
    "    if is_ascii(semantic_score_dic[sorted(semantic_score_dic.keys(), reverse=True)[i+off_set]]):\n",
    "        w2v_recom.append(semantic_score_dic[sorted(semantic_score_dic.keys(), reverse=True)[i+off_set]])\n",
    "    else:\n",
    "        off_set += 1\n",
    "        w2v_recom.append(semantic_score_dic[sorted(semantic_score_dic.keys(), reverse=True)[i+off_set]])\n",
    "        \n",
    "semantic_score_rev_dic = {}\n",
    "for key, value in semantic_score_dic.items():\n",
    "    semantic_score_rev_dic[value] = key\n",
    "    \n",
    "LDA_results['w2v_cos_similarity'] = LDA_results.course_name.apply(get_cos_similariy)\n",
    "LDA_results['weighted_cs'] = (LDA_results.cos_similarity + LDA_results.w2v_cos_similarity)/2\n",
    "print LDA_results.sort('weighted_cs', ascending=False).course_name.iloc[:num_to_recommend].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Learn to Play French Horn: Beginner to Pro Made the Easy Way'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " - [input_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recom_results = LDA_results.sort('weighted_cs', ascending=False).course_name.iloc[:num_to_recommend+5].values\n",
    "recom_results = [x for x in recom_results if x != input_string]\n",
    "\n",
    "recom_results[:num_to_recommend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Learn to Play Euphonium: Beginner to Pro in Under Five Hours',\n",
       " u'Master Flute Playing: Intermediate Instruction Made Simple!',\n",
       " u'From the Repertoire: Western Music History through Performance',\n",
       " u\"Music's Big Bang: The Genesis of Rock 'n' Roll\",\n",
       " u'20\\u4e16\\u7eaa\\u897f\\u65b9\\u97f3\\u4e50 Western Music in the 20th Century',\n",
       " u'Introduction to Classical Music',\n",
       " u'Listening to World Music',\n",
       " u'Curanderismo Part 2: Traditional Healing of the Spirit/Energy',\n",
       " u'Magic in the Middle Ages',\n",
       " u'Curanderismo Part 1: Traditional Healing of the Body']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'Giving Feedback That Gets Results',\n",
       "       u'Making the Connection: A Guide To Networking',\n",
       "       u'Lead the Way - Building Leadership Capability',\n",
       "       u'Meetings That Get Results', u'Robust Scrum Master',\n",
       "       u\"Sock it to 'Em! Powerful Presentations\"], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LDA_results = pd.read_csv('LDA_results_CEU_26_topics.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
